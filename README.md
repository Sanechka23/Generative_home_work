Задача детекции анамалий.

Архитектура 1: Автоэнкодер Гипперпараметры: оптимизатор - AdamW, loss - MSE, lr - 0.003, epoch - 10
Архитектура 2: Многослойный автоэнкодер  Гипперпараметры: оптимизатор - Adam, loss - MSE, lr - 0.0004, epoch - 10

для каждой архитектуры имеются два классификатора, основанные на значениях mse для набора с проливами. 
Первый классификатор задает две границы для диапозона местонахождения mse, соответствующих проливам,
а второй только одну границу.

Граффики val_loss, train_loss приведены в блокноте Colab

Значения точнсти:
|  | архит. 1, классиф. 1 | архит. 1, классиф. 2 | архит. 2, классиф. 1 | архит. 2, классиф. 2 |
| ---------- | ------------------- | --- | ------------- | --------|
| TPR | 0.6899 | 0.6202 | 0.8837 | 0.6511 |
| TNR | 0.8619 | 0.9735 | 0.7861 | 0.9907 |

Как видно из таблицы 2ой классификатор слишком много предсказывает элементов класса "0", 
что отражается в большом количестве ложноотрицательных элементов. 
Также можно заметить, что классификатор 1 на архитектуре 2 показал более корректное 
распредление по классам, чем тот же классификатор на архитектуре 1. По этой причине
были скоректированы границы классификации именно для архит. 2, классиф. 1 с целью
получить приблизительно равнозначные TNR и TPR. 
В итоге: TPR = 0.8295, TNR = 0.8207

Ссылка на блокнот: https://colab.research.google.com/drive/18hSP7rvDIZMZAZzYLKza0n4T7OG1WqCX?usp=sharing
